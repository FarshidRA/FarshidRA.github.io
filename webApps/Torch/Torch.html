<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>Interactive Object Detection 3:4</title>
<style>
  body {
    margin:0;
    display:flex;
    justify-content:center;
    align-items:center;
    height:100vh;
    background:#000;
  }
  #container {
    position:relative;
    width:360px;
    height:480px; /* 3:4 aspect ratio */
    background:#000;
    overflow:hidden;
    display:flex;
    justify-content:center;
    align-items:center;
  }
  video#cam {
    display:block;
    position:absolute;
    top:0;
    left:0;
    width:100%;
    height:100%;
    object-fit:cover; /* fill container without stretching */
  }
  canvas#overlay {
    position:absolute;
    top:0;
    left:0;
    touch-action: none;
    width:100%;
    height:100%;
  }
</style>
</head>
<body>
<div id="container">
  <video id="cam" autoplay playsinline></video>
  <canvas id="overlay"></canvas>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.7.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
<script>
(async ()=>{
const video = document.getElementById('cam');
const canvas = document.getElementById('overlay');
const ctx = canvas.getContext('2d');
let model;
let boxes = []; // persistent boxes

// camera access
try {
  const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false });
  video.srcObject = stream;
  await video.play();
} catch(e){
  alert('Camera access not available.');
  return;
}

// adjust canvas size to container
function resizeCanvas() {
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
}
video.addEventListener('loadedmetadata', resizeCanvas);
window.addEventListener('resize', resizeCanvas);

// load model
model = await cocoSsd.load();
console.log('Model loaded');

// dragging state
let dragging = null;
let offset = {x:0, y:0};

// pointer events
canvas.addEventListener('pointerdown', e => {
  const rect = canvas.getBoundingClientRect();
  const x = (e.clientX - rect.left) * (canvas.width/rect.width);
  const y = (e.clientY - rect.top) * (canvas.height/rect.height);

  for(let i=boxes.length-1;i>=0;i--){
    const b = boxes[i];
    if(x>=b.x && x<=b.x+b.w && y>=b.y && y<=b.y+b.h){
      dragging = b;
      offset.x = x - b.x;
      offset.y = y - b.y;
      return;
    }
  }
});

canvas.addEventListener('pointermove', e => {
  if(dragging){
    const rect = canvas.getBoundingClientRect();
    const x = (e.clientX - rect.left) * (canvas.width/rect.width);
    const y = (e.clientY - rect.top) * (canvas.height/rect.height);
    dragging.x = x - offset.x;
    dragging.y = y - offset.y;
  }
});

canvas.addEventListener('pointerup', e => { dragging = null; });
canvas.addEventListener('pointerleave', e => { dragging = null; });

// detection loop
async function detectLoop(){
  if(video.readyState === 4){
    const predictions = await model.detect(video);

    // update boxes but keep dragged positions
    for(const p of predictions){
      const exists = boxes.find(b => b.class === p.class && b.score === p.score);
      if(!exists){
        boxes.push({
          x: p.bbox[0],
          y: p.bbox[1],
          w: p.bbox[2],
          h: p.bbox[3],
          class: p.class,
          score: p.score
        });
      }
    }

    // clear canvas
    ctx.clearRect(0,0,canvas.width,canvas.height);

    // draw boxes
    for(const b of boxes){
      if(b.w<=0 || b.h<=0) continue; // safety
      let color;
      if(b.score<0.5) color='red';
      else if(b.score<0.8) color='yellow';
      else color='lime';

      ctx.strokeStyle=color;
      ctx.lineWidth=2;
      ctx.strokeRect(b.x,b.y,b.w,b.h);

      ctx.fillStyle=color;
      ctx.font='14px sans-serif';
      ctx.fillText(b.class + ' ' + Math.round(b.score*100)+'%', b.x+4, b.y+16);
    }
  }
  requestAnimationFrame(detectLoop);
}

detectLoop();
})();
</script>
</body>
</html>
